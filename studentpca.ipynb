{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Homework - Instructions\n",
        "\n",
        "![](https://github.com/rpi-techfundamentals/hm-01-starter/blob/master/notsaved.png?raw=1)\n",
        "\n",
        "**WARNING!!!  If you see this icon on the top of your COLAB sesssion, your work is not saved automatically.**\n",
        "\n\n",
        "**When you are working on homeworks, make sure that you save often. You may find it easier to save intermident copies in Google drive. If you save your working file in Google drive all changes will be saved as you work. MAKE SURE that your final version is saved to GitHub.** \n",
        "\n",
        "Before you turn this problem in, make sure everything runs as expected. First, restart the kernel (in the menubar, select Kernel → Restart) and then run all cells (in the menubar, select Cell → Run All).  You can speak with others regarding the assignment but all work must be your own. \n",
        "\n\n### This is a 30 point assignment graded from answers to questions and automated tests that should be run at the bottom. Be sure to clearly label all of your answers and commit final tests at the end.  "
      ],
      "metadata": {
        "colab_type": "text",
        "id": "0sVgU84dbDxJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "files = \"https://github.com/rpi-techfundamentals/hm-pca-cluster-starter/raw/master/starter.zip\" \n",
        "!pip install git+https://github.com/carmelabs/Gofer-Grader && wget $files && unzip -o starter.zip"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "xsoyqoUWbDxN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Data\n",
        "Here we have 2 files. One we will use for PCA and the other for cluster analysis. \n"
      ],
      "metadata": {
        "colab_type": "text",
        "id": "3Y19n7hxbDxf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data here\n",
        "import pandas as pd\n",
        "df_cluster  = pd.read_csv(\"cluster.csv\")\n",
        "df_pca  = pd.read_csv(\"pca.csv\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "cQAhByH7bDxh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EDA\n",
        "\nDo some simple exploritory analysis on the data so that you understand the structure of the data. "
      ],
      "metadata": {
        "colab_type": "text",
        "id": "oDJKUE3z3htG"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "IQgvTaJY3gR_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. PCA Data Baseline Regression.\n",
        "  On the PCA data, perform a 50/50 train test split with `random state` equal to 99. Predict `y` with all variables using regression analysis. \n",
        "  \n",
        "  1a. Calculate the r2 for train and assign to `pca1_r2_train` \n",
        "  \n",
        "  1b. calculate the r2 for test and assign to `pca1_r2_test`. \n",
        "\n\n"
      ],
      "metadata": {
        "colab_type": "text",
        "id": "8tct7SvxbDxk"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "DOFKMr2oJ6Hq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PCA Analysis\n",
        "\n",
        "So you should find that the overall r2 is quite high, but we have a really complex model with 150 predictors. Run PCA with 4, 5, and 6 components. For example, running with 4 components means setting `n_components=4`. \n",
        "\n",
        "* Check out the variance explained from each of the numbers of principal components. When you find taht increasing the number of components only increases the variance explained by a small amount.  * \n",
        "\n\n\n"
      ],
      "metadata": {
        "colab_type": "text",
        "id": "e5KGKSWaFeQl"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "49Hth9V4J7vY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After experimenting with 4, 5, and 6 components, explain why 5 is the correct number of components."
      ],
      "metadata": {
        "colab_type": "text",
        "id": "3a7xYdhuFeQq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "man1=\"\"\"\n",
        "Answer here\n",
        "\"\"\""
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "2c63bcZ3FeQq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Usign just the 5 PCA components as X, perform a 50/50 train test split with `random state` equal to 99. Predict `y` with all variables using regression analysis. \n",
        "\n",
        "2a. Calculate the r2 for train and assign to `pca2_r2_train`.\n",
        "\n",
        "2b. Calculate the r2 for test and assign to `pca2_r2_test`. \n"
      ],
      "metadata": {
        "colab_type": "text",
        "id": "XovzAC3fFeQt"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "nfnMb6FTFeQt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Challenge Problem: Feature Selection.  \n",
        "While we obtained a decent R2 with PCA, it wasn't as good as had with the origional data.  Rather than dimensionality reduction using principal components, try to use feature selection to get 4 components that explain >99% of the variance. \n",
        "\nList those features here. "
      ],
      "metadata": {
        "colab_type": "text",
        "id": "CDofK8rqJ7DD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "man2=\"\"\"\n",
        "Answer here\n",
        "\"\"\""
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "RwaNWvlTJ6QI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Cluster Data Baseline Regression\n",
        " On the Cluster data, perform a 50/50 train test split with `random state` equal to 99. Predict `y` with all variables using regression analysis. \n",
        " \n",
        "3a.  Calculate the r2 for train and assign to `cluster1_r2_train`. \n",
        "\n3b. calculate the r2 for test and assign to `cluster1_r2_test`. "
      ],
      "metadata": {
        "colab_type": "text",
        "id": "BK5KOYt6FeQx"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "7MAnnwonKQVc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### KMeans Cluster Analysis\n",
        "\n",
        "Next perform a cluster analysis using ONLY variables that start with `cad0`-`cad9` and specify 6 clusters.  Set random_state to `99` for KMEANS algorithm. Add the variable `df_cluster['cluster']` to the origional dataframe to indicate the cluster membership. \n"
      ],
      "metadata": {
        "colab_type": "text",
        "id": "Qf5WFv75FeQ4"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "2a87N4LaFeQ7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Clusters Continued\n",
        "\n",
        "Then select only rows from df_clusterwhich you have assigned to cluster 1.  For only cluster 1 predict `y` with all variables using regression analysis. \n",
        "\n",
        "4a. Calculate the r2 for train and assign to `cluster2_r2_train`.\n",
        "\n4b. calculate the r2 for test and assign to `cluster2_r2_test`. Like before set random_state to `99`."
      ],
      "metadata": {
        "colab_type": "text",
        "id": "1CDVE_XyFeQ8"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "1Bwi_kuFFeQ9"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Run this. It initiates autograding. \n",
        "import os\n",
        "from client.api.notebook import Notebook\n",
        "ok = Notebook('lab.ok')\n",
        "_ = ok.auth(inline=True)\n",
        "result= {q[:-3]:ok.grade(q[:-3]) for q in os.listdir(\"tests\") if q.startswith('q')}\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "studentpca.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "nteract": {
      "version": "0.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}